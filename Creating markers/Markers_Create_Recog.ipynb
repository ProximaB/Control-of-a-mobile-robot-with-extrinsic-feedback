{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import os\n",
    "clear = lambda: os.system('cls')\n",
    "clear()\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module cv2.aruco in cv2:\n",
      "\n",
      "NAME\n",
      "    cv2.aruco\n",
      "\n",
      "FUNCTIONS\n",
      "    Board_create(...)\n",
      "        Board_create(objPoints, dictionary, ids) -> retval\n",
      "        .   * @brief Provide way to create Board by passing nessesary data. Specially needed in Python.\n",
      "        .   *\n",
      "        .   * @param objPoints array of object points of all the marker corners in the board\n",
      "        .   * @param dictionary the dictionary of markers employed for this board\n",
      "        .   * @param ids vector of the identifiers of the markers in the board\n",
      "        .   *\n",
      "    \n",
      "    CharucoBoard_create(...)\n",
      "        CharucoBoard_create(squaresX, squaresY, squareLength, markerLength, dictionary) -> retval\n",
      "        .   * @brief Create a CharucoBoard object\n",
      "        .   *\n",
      "        .   * @param squaresX number of chessboard squares in X direction\n",
      "        .   * @param squaresY number of chessboard squares in Y direction\n",
      "        .   * @param squareLength chessboard square side length (normally in meters)\n",
      "        .   * @param markerLength marker side length (same unit than squareLength)\n",
      "        .   * @param dictionary dictionary of markers indicating the type of markers.\n",
      "        .   * The first markers in the dictionary are used to fill the white chessboard squares.\n",
      "        .   * @return the output CharucoBoard object\n",
      "        .   *\n",
      "        .   * This functions creates a CharucoBoard object given the number of squares in each direction\n",
      "        .   * and the size of the markers and chessboard squares.\n",
      "    \n",
      "    DetectorParameters_create(...)\n",
      "        DetectorParameters_create() -> retval\n",
      "        .\n",
      "    \n",
      "    Dictionary_create(...)\n",
      "        Dictionary_create(nMarkers, markerSize) -> retval\n",
      "        .   * @see generateCustomDictionary\n",
      "    \n",
      "    Dictionary_create_from(...)\n",
      "        Dictionary_create_from(nMarkers, markerSize, baseDictionary) -> retval\n",
      "        .   * @see generateCustomDictionary\n",
      "    \n",
      "    Dictionary_get(...)\n",
      "        Dictionary_get(dict) -> retval\n",
      "        .   * @see getPredefinedDictionary\n",
      "    \n",
      "    Dictionary_getBitsFromByteList(...)\n",
      "        Dictionary_getBitsFromByteList(byteList, markerSize) -> retval\n",
      "        .   * @brief Transform list of bytes to matrix of bits\n",
      "    \n",
      "    Dictionary_getByteListFromBits(...)\n",
      "        Dictionary_getByteListFromBits(bits) -> retval\n",
      "        .   * @brief Transform matrix of bits to list of bytes in the 4 rotations\n",
      "    \n",
      "    GridBoard_create(...)\n",
      "        GridBoard_create(markersX, markersY, markerLength, markerSeparation, dictionary[, firstMarker]) -> retval\n",
      "        .   * @brief Create a GridBoard object\n",
      "        .   *\n",
      "        .   * @param markersX number of markers in X direction\n",
      "        .   * @param markersY number of markers in Y direction\n",
      "        .   * @param markerLength marker side length (normally in meters)\n",
      "        .   * @param markerSeparation separation between two markers (same unit as markerLength)\n",
      "        .   * @param dictionary dictionary of markers indicating the type of markers\n",
      "        .   * @param firstMarker id of first marker in dictionary to use on board.\n",
      "        .   * @return the output GridBoard object\n",
      "        .   *\n",
      "        .   * This functions creates a GridBoard object given the number of markers in each direction and\n",
      "        .   * the marker size and marker separation.\n",
      "    \n",
      "    calibrateCameraAruco(...)\n",
      "        calibrateCameraAruco(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs\n",
      "        .   @brief It's the same function as #calibrateCameraAruco but without calibration error estimation.\n",
      "    \n",
      "    calibrateCameraArucoExtended(...)\n",
      "        calibrateCameraArucoExtended(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n",
      "        .   * @brief Calibrate a camera using aruco markers\n",
      "        .   *\n",
      "        .   * @param corners vector of detected marker corners in all frames.\n",
      "        .   * The corners should have the same format returned by detectMarkers (see #detectMarkers).\n",
      "        .   * @param ids list of identifiers for each marker in corners\n",
      "        .   * @param counter number of markers in each frame so that corners and ids can be split\n",
      "        .   * @param board Marker Board layout\n",
      "        .   * @param imageSize Size of the image used only to initialize the intrinsic camera matrix.\n",
      "        .   * @param cameraMatrix Output 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ . If CV\\_CALIB\\_USE\\_INTRINSIC\\_GUESS\n",
      "        .   * and/or CV_CALIB_FIX_ASPECT_RATIO are specified, some or all of fx, fy, cx, cy must be\n",
      "        .   * initialized before calling the function.\n",
      "        .   * @param distCoeffs Output vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   * @param rvecs Output vector of rotation vectors (see Rodrigues ) estimated for each board view\n",
      "        .   * (e.g. std::vector<cv::Mat>>). That is, each k-th rotation vector together with the corresponding\n",
      "        .   * k-th translation vector (see the next output parameter description) brings the board pattern\n",
      "        .   * from the model coordinate space (in which object points are specified) to the world coordinate\n",
      "        .   * space, that is, a real position of the board pattern in the k-th pattern view (k=0.. *M* -1).\n",
      "        .   * @param tvecs Output vector of translation vectors estimated for each pattern view.\n",
      "        .   * @param stdDeviationsIntrinsics Output vector of standard deviations estimated for intrinsic parameters.\n",
      "        .   * Order of deviations values:\n",
      "        .   * \\f$(f_x, f_y, c_x, c_y, k_1, k_2, p_1, p_2, k_3, k_4, k_5, k_6 , s_1, s_2, s_3,\n",
      "        .   * s_4, \\tau_x, \\tau_y)\\f$ If one of parameters is not estimated, it's deviation is equals to zero.\n",
      "        .   * @param stdDeviationsExtrinsics Output vector of standard deviations estimated for extrinsic parameters.\n",
      "        .   * Order of deviations values: \\f$(R_1, T_1, \\dotsc , R_M, T_M)\\f$ where M is number of pattern views,\n",
      "        .   * \\f$R_i, T_i\\f$ are concatenated 1x3 vectors.\n",
      "        .   * @param perViewErrors Output vector of average re-projection errors estimated for each pattern view.\n",
      "        .   * @param flags flags Different flags  for the calibration process (see #calibrateCamera for details).\n",
      "        .   * @param criteria Termination criteria for the iterative optimization algorithm.\n",
      "        .   *\n",
      "        .   * This function calibrates a camera using an Aruco Board. The function receives a list of\n",
      "        .   * detected markers from several views of the Board. The process is similar to the chessboard\n",
      "        .   * calibration in calibrateCamera(). The function returns the final re-projection error.\n",
      "    \n",
      "    calibrateCameraCharuco(...)\n",
      "        calibrateCameraCharuco(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs\n",
      "        .   @brief It's the same function as #calibrateCameraCharuco but without calibration error estimation.\n",
      "    \n",
      "    calibrateCameraCharucoExtended(...)\n",
      "        calibrateCameraCharucoExtended(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n",
      "        .   * @brief Calibrate a camera using Charuco corners\n",
      "        .   *\n",
      "        .   * @param charucoCorners vector of detected charuco corners per frame\n",
      "        .   * @param charucoIds list of identifiers for each corner in charucoCorners per frame\n",
      "        .   * @param board Marker Board layout\n",
      "        .   * @param imageSize input image size\n",
      "        .   * @param cameraMatrix Output 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ . If CV\\_CALIB\\_USE\\_INTRINSIC\\_GUESS\n",
      "        .   * and/or CV_CALIB_FIX_ASPECT_RATIO are specified, some or all of fx, fy, cx, cy must be\n",
      "        .   * initialized before calling the function.\n",
      "        .   * @param distCoeffs Output vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   * @param rvecs Output vector of rotation vectors (see Rodrigues ) estimated for each board view\n",
      "        .   * (e.g. std::vector<cv::Mat>>). That is, each k-th rotation vector together with the corresponding\n",
      "        .   * k-th translation vector (see the next output parameter description) brings the board pattern\n",
      "        .   * from the model coordinate space (in which object points are specified) to the world coordinate\n",
      "        .   * space, that is, a real position of the board pattern in the k-th pattern view (k=0.. *M* -1).\n",
      "        .   * @param tvecs Output vector of translation vectors estimated for each pattern view.\n",
      "        .   * @param stdDeviationsIntrinsics Output vector of standard deviations estimated for intrinsic parameters.\n",
      "        .   * Order of deviations values:\n",
      "        .   * \\f$(f_x, f_y, c_x, c_y, k_1, k_2, p_1, p_2, k_3, k_4, k_5, k_6 , s_1, s_2, s_3,\n",
      "        .   * s_4, \\tau_x, \\tau_y)\\f$ If one of parameters is not estimated, it's deviation is equals to zero.\n",
      "        .   * @param stdDeviationsExtrinsics Output vector of standard deviations estimated for extrinsic parameters.\n",
      "        .   * Order of deviations values: \\f$(R_1, T_1, \\dotsc , R_M, T_M)\\f$ where M is number of pattern views,\n",
      "        .   * \\f$R_i, T_i\\f$ are concatenated 1x3 vectors.\n",
      "        .   * @param perViewErrors Output vector of average re-projection errors estimated for each pattern view.\n",
      "        .   * @param flags flags Different flags  for the calibration process (see #calibrateCamera for details).\n",
      "        .   * @param criteria Termination criteria for the iterative optimization algorithm.\n",
      "        .   *\n",
      "        .   * This function calibrates a camera using a set of corners of a  Charuco Board. The function\n",
      "        .   * receives a list of detected corners and its identifiers from several views of the Board.\n",
      "        .   * The function returns the final re-projection error.\n",
      "    \n",
      "    custom_dictionary(...)\n",
      "        custom_dictionary(nMarkers, markerSize) -> retval\n",
      "        .   * @see generateCustomDictionary\n",
      "    \n",
      "    custom_dictionary_from(...)\n",
      "        custom_dictionary_from(nMarkers, markerSize, baseDictionary) -> retval\n",
      "        .   * @brief Generates a new customizable marker dictionary\n",
      "        .   *\n",
      "        .   * @param nMarkers number of markers in the dictionary\n",
      "        .   * @param markerSize number of bits per dimension of each markers\n",
      "        .   * @param baseDictionary Include the markers in this dictionary at the beginning (optional)\n",
      "        .   *\n",
      "        .   * This function creates a new dictionary composed by nMarkers markers and each markers composed\n",
      "        .   * by markerSize x markerSize bits. If baseDictionary is provided, its markers are directly\n",
      "        .   * included and the rest are generated based on them. If the size of baseDictionary is higher\n",
      "        .   * than nMarkers, only the first nMarkers in baseDictionary are taken and no new marker is added.\n",
      "    \n",
      "    detectCharucoDiamond(...)\n",
      "        detectCharucoDiamond(image, markerCorners, markerIds, squareMarkerLengthRate[, diamondCorners[, diamondIds[, cameraMatrix[, distCoeffs]]]]) -> diamondCorners, diamondIds\n",
      "        .   * @brief Detect ChArUco Diamond markers\n",
      "        .   *\n",
      "        .   * @param image input image necessary for corner subpixel.\n",
      "        .   * @param markerCorners list of detected marker corners from detectMarkers function.\n",
      "        .   * @param markerIds list of marker ids in markerCorners.\n",
      "        .   * @param squareMarkerLengthRate rate between square and marker length:\n",
      "        .   * squareMarkerLengthRate = squareLength/markerLength. The real units are not necessary.\n",
      "        .   * @param diamondCorners output list of detected diamond corners (4 corners per diamond). The order\n",
      "        .   * is the same than in marker corners: top left, top right, bottom right and bottom left. Similar\n",
      "        .   * format than the corners returned by detectMarkers (e.g std::vector<std::vector<cv::Point2f> > ).\n",
      "        .   * @param diamondIds ids of the diamonds in diamondCorners. The id of each diamond is in fact of\n",
      "        .   * type Vec4i, so each diamond has 4 ids, which are the ids of the aruco markers composing the\n",
      "        .   * diamond.\n",
      "        .   * @param cameraMatrix Optional camera calibration matrix.\n",
      "        .   * @param distCoeffs Optional camera distortion coefficients.\n",
      "        .   *\n",
      "        .   * This function detects Diamond markers from the previous detected ArUco markers. The diamonds\n",
      "        .   * are returned in the diamondCorners and diamondIds parameters. If camera calibration parameters\n",
      "        .   * are provided, the diamond search is based on reprojection. If not, diamond search is based on\n",
      "        .   * homography. Homography is faster than reprojection but can slightly reduce the detection rate.\n",
      "    \n",
      "    detectMarkers(...)\n",
      "        detectMarkers(image, dictionary[, corners[, ids[, parameters[, rejectedImgPoints[, cameraMatrix[, distCoeff]]]]]]) -> corners, ids, rejectedImgPoints\n",
      "        .   * @brief Basic marker detection\n",
      "        .   *\n",
      "        .   * @param image input image\n",
      "        .   * @param dictionary indicates the type of markers that will be searched\n",
      "        .   * @param corners vector of detected marker corners. For each marker, its four corners\n",
      "        .   * are provided, (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers,\n",
      "        .   * the dimensions of this array is Nx4. The order of the corners is clockwise.\n",
      "        .   * @param ids vector of identifiers of the detected markers. The identifier is of type int\n",
      "        .   * (e.g. std::vector<int>). For N detected markers, the size of ids is also N.\n",
      "        .   * The identifiers have the same order than the markers in the imgPoints array.\n",
      "        .   * @param parameters marker detection parameters\n",
      "        .   * @param rejectedImgPoints contains the imgPoints of those squares whose inner code has not a\n",
      "        .   * correct codification. Useful for debugging purposes.\n",
      "        .   * @param cameraMatrix optional input 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   * @param distCoeff optional vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   *\n",
      "        .   * Performs marker detection in the input image. Only markers included in the specific dictionary\n",
      "        .   * are searched. For each detected marker, it returns the 2D position of its corner in the image\n",
      "        .   * and its corresponding identifier.\n",
      "        .   * Note that this function does not perform pose estimation.\n",
      "        .   * @sa estimatePoseSingleMarkers,  estimatePoseBoard\n",
      "        .   *\n",
      "    \n",
      "    drawAxis(...)\n",
      "        drawAxis(image, cameraMatrix, distCoeffs, rvec, tvec, length) -> image\n",
      "        .   * @brief Draw coordinate system axis from pose estimation\n",
      "        .   *\n",
      "        .   * @param image input/output image. It must have 1 or 3 channels. The number of channels is not\n",
      "        .   * altered.\n",
      "        .   * @param cameraMatrix input 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   * @param distCoeffs vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   * @param rvec rotation vector of the coordinate system that will be drawn. (@sa Rodrigues).\n",
      "        .   * @param tvec translation vector of the coordinate system that will be drawn.\n",
      "        .   * @param length length of the painted axis in the same unit than tvec (usually in meters)\n",
      "        .   *\n",
      "        .   * Given the pose estimation of a marker or board, this function draws the axis of the world\n",
      "        .   * coordinate system, i.e. the system centered on the marker/board. Useful for debugging purposes.\n",
      "    \n",
      "    drawDetectedCornersCharuco(...)\n",
      "        drawDetectedCornersCharuco(image, charucoCorners[, charucoIds[, cornerColor]]) -> image\n",
      "        .   * @brief Draws a set of Charuco corners\n",
      "        .   * @param image input/output image. It must have 1 or 3 channels. The number of channels is not\n",
      "        .   * altered.\n",
      "        .   * @param charucoCorners vector of detected charuco corners\n",
      "        .   * @param charucoIds list of identifiers for each corner in charucoCorners\n",
      "        .   * @param cornerColor color of the square surrounding each corner\n",
      "        .   *\n",
      "        .   * This function draws a set of detected Charuco corners. If identifiers vector is provided, it also\n",
      "        .   * draws the id of each corner.\n",
      "    \n",
      "    drawDetectedDiamonds(...)\n",
      "        drawDetectedDiamonds(image, diamondCorners[, diamondIds[, borderColor]]) -> image\n",
      "        .   * @brief Draw a set of detected ChArUco Diamond markers\n",
      "        .   *\n",
      "        .   * @param image input/output image. It must have 1 or 3 channels. The number of channels is not\n",
      "        .   * altered.\n",
      "        .   * @param diamondCorners positions of diamond corners in the same format returned by\n",
      "        .   * detectCharucoDiamond(). (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers,\n",
      "        .   * the dimensions of this array should be Nx4. The order of the corners should be clockwise.\n",
      "        .   * @param diamondIds vector of identifiers for diamonds in diamondCorners, in the same format\n",
      "        .   * returned by detectCharucoDiamond() (e.g. std::vector<Vec4i>).\n",
      "        .   * Optional, if not provided, ids are not painted.\n",
      "        .   * @param borderColor color of marker borders. Rest of colors (text color and first corner color)\n",
      "        .   * are calculated based on this one.\n",
      "        .   *\n",
      "        .   * Given an array of detected diamonds, this functions draws them in the image. The marker borders\n",
      "        .   * are painted and the markers identifiers if provided.\n",
      "        .   * Useful for debugging purposes.\n",
      "    \n",
      "    drawDetectedMarkers(...)\n",
      "        drawDetectedMarkers(image, corners[, ids[, borderColor]]) -> image\n",
      "        .   * @brief Draw detected markers in image\n",
      "        .   *\n",
      "        .   * @param image input/output image. It must have 1 or 3 channels. The number of channels is not\n",
      "        .   * altered.\n",
      "        .   * @param corners positions of marker corners on input image.\n",
      "        .   * (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers, the dimensions of\n",
      "        .   * this array should be Nx4. The order of the corners should be clockwise.\n",
      "        .   * @param ids vector of identifiers for markers in markersCorners .\n",
      "        .   * Optional, if not provided, ids are not painted.\n",
      "        .   * @param borderColor color of marker borders. Rest of colors (text color and first corner color)\n",
      "        .   * are calculated based on this one to improve visualization.\n",
      "        .   *\n",
      "        .   * Given an array of detected marker corners and its corresponding ids, this functions draws\n",
      "        .   * the markers in the image. The marker borders are painted and the markers identifiers if provided.\n",
      "        .   * Useful for debugging purposes.\n",
      "    \n",
      "    drawMarker(...)\n",
      "        drawMarker(dictionary, id, sidePixels[, img[, borderBits]]) -> img\n",
      "        .   * @brief Draw a canonical marker image\n",
      "        .   *\n",
      "        .   * @param dictionary dictionary of markers indicating the type of markers\n",
      "        .   * @param id identifier of the marker that will be returned. It has to be a valid id\n",
      "        .   * in the specified dictionary.\n",
      "        .   * @param sidePixels size of the image in pixels\n",
      "        .   * @param img output image with the marker\n",
      "        .   * @param borderBits width of the marker border.\n",
      "        .   *\n",
      "        .   * This function returns a marker image in its canonical form (i.e. ready to be printed)\n",
      "    \n",
      "    drawPlanarBoard(...)\n",
      "        drawPlanarBoard(board, outSize[, img[, marginSize[, borderBits]]]) -> img\n",
      "        .   * @brief Draw a planar board\n",
      "        .   * @sa _drawPlanarBoardImpl\n",
      "        .   *\n",
      "        .   * @param board layout of the board that will be drawn. The board should be planar,\n",
      "        .   * z coordinate is ignored\n",
      "        .   * @param outSize size of the output image in pixels.\n",
      "        .   * @param img output image with the board. The size of this image will be outSize\n",
      "        .   * and the board will be on the center, keeping the board proportions.\n",
      "        .   * @param marginSize minimum margins (in pixels) of the board in the output image\n",
      "        .   * @param borderBits width of the marker borders.\n",
      "        .   *\n",
      "        .   * This function return the image of a planar board, ready to be printed. It assumes\n",
      "        .   * the Board layout specified is planar by ignoring the z coordinates of the object points.\n",
      "    \n",
      "    estimatePoseBoard(...)\n",
      "        estimatePoseBoard(corners, ids, board, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess]]]) -> retval, rvec, tvec\n",
      "        .   * @brief Pose estimation for a board of markers\n",
      "        .   *\n",
      "        .   * @param corners vector of already detected markers corners. For each marker, its four corners\n",
      "        .   * are provided, (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers, the\n",
      "        .   * dimensions of this array should be Nx4. The order of the corners should be clockwise.\n",
      "        .   * @param ids list of identifiers for each marker in corners\n",
      "        .   * @param board layout of markers in the board. The layout is composed by the marker identifiers\n",
      "        .   * and the positions of each marker corner in the board reference system.\n",
      "        .   * @param cameraMatrix input 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   * @param distCoeffs vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   * @param rvec Output vector (e.g. cv::Mat) corresponding to the rotation vector of the board\n",
      "        .   * (see cv::Rodrigues). Used as initial guess if not empty.\n",
      "        .   * @param tvec Output vector (e.g. cv::Mat) corresponding to the translation vector of the board.\n",
      "        .   * @param useExtrinsicGuess defines whether initial guess for \\b rvec and \\b tvec will be used or not.\n",
      "        .   * Used as initial guess if not empty.\n",
      "        .   *\n",
      "        .   * This function receives the detected markers and returns the pose of a marker board composed\n",
      "        .   * by those markers.\n",
      "        .   * A Board of marker has a single world coordinate system which is defined by the board layout.\n",
      "        .   * The returned transformation is the one that transforms points from the board coordinate system\n",
      "        .   * to the camera coordinate system.\n",
      "        .   * Input markers that are not included in the board layout are ignored.\n",
      "        .   * The function returns the number of markers from the input employed for the board pose estimation.\n",
      "        .   * Note that returning a 0 means the pose has not been estimated.\n",
      "    \n",
      "    estimatePoseCharucoBoard(...)\n",
      "        estimatePoseCharucoBoard(charucoCorners, charucoIds, board, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess]]]) -> retval, rvec, tvec\n",
      "        .   * @brief Pose estimation for a ChArUco board given some of their corners\n",
      "        .   * @param charucoCorners vector of detected charuco corners\n",
      "        .   * @param charucoIds list of identifiers for each corner in charucoCorners\n",
      "        .   * @param board layout of ChArUco board.\n",
      "        .   * @param cameraMatrix input 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   * @param distCoeffs vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   * @param rvec Output vector (e.g. cv::Mat) corresponding to the rotation vector of the board\n",
      "        .   * (see cv::Rodrigues).\n",
      "        .   * @param tvec Output vector (e.g. cv::Mat) corresponding to the translation vector of the board.\n",
      "        .   * @param useExtrinsicGuess defines whether initial guess for \\b rvec and \\b tvec will be used or not.\n",
      "        .   *\n",
      "        .   * This function estimates a Charuco board pose from some detected corners.\n",
      "        .   * The function checks if the input corners are enough and valid to perform pose estimation.\n",
      "        .   * If pose estimation is valid, returns true, else returns false.\n",
      "    \n",
      "    estimatePoseSingleMarkers(...)\n",
      "        estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs[, rvecs[, tvecs[, _objPoints]]]) -> rvecs, tvecs, _objPoints\n",
      "        .   * @brief Pose estimation for single markers\n",
      "        .   *\n",
      "        .   * @param corners vector of already detected markers corners. For each marker, its four corners\n",
      "        .   * are provided, (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers,\n",
      "        .   * the dimensions of this array should be Nx4. The order of the corners should be clockwise.\n",
      "        .   * @sa detectMarkers\n",
      "        .   * @param markerLength the length of the markers' side. The returning translation vectors will\n",
      "        .   * be in the same unit. Normally, unit is meters.\n",
      "        .   * @param cameraMatrix input 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   * @param distCoeffs vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   * @param rvecs array of output rotation vectors (@sa Rodrigues) (e.g. std::vector<cv::Vec3d>).\n",
      "        .   * Each element in rvecs corresponds to the specific marker in imgPoints.\n",
      "        .   * @param tvecs array of output translation vectors (e.g. std::vector<cv::Vec3d>).\n",
      "        .   * Each element in tvecs corresponds to the specific marker in imgPoints.\n",
      "        .   * @param _objPoints array of object points of all the marker corners\n",
      "        .   *\n",
      "        .   * This function receives the detected markers and returns their pose estimation respect to\n",
      "        .   * the camera individually. So for each marker, one rotation and translation vector is returned.\n",
      "        .   * The returned transformation is the one that transforms points from each marker coordinate system\n",
      "        .   * to the camera coordinate system.\n",
      "        .   * The marker corrdinate system is centered on the middle of the marker, with the Z axis\n",
      "        .   * perpendicular to the marker plane.\n",
      "        .   * The coordinates of the four corners of the marker in its own coordinate system are:\n",
      "        .   * (-markerLength/2, markerLength/2, 0), (markerLength/2, markerLength/2, 0),\n",
      "        .   * (markerLength/2, -markerLength/2, 0), (-markerLength/2, -markerLength/2, 0)\n",
      "    \n",
      "    getBoardObjectAndImagePoints(...)\n",
      "        getBoardObjectAndImagePoints(board, detectedCorners, detectedIds[, objPoints[, imgPoints]]) -> objPoints, imgPoints\n",
      "        .   * @brief Given a board configuration and a set of detected markers, returns the corresponding\n",
      "        .   * image points and object points to call solvePnP\n",
      "        .   *\n",
      "        .   * @param board Marker board layout.\n",
      "        .   * @param detectedCorners List of detected marker corners of the board.\n",
      "        .   * @param detectedIds List of identifiers for each marker.\n",
      "        .   * @param objPoints Vector of vectors of board marker points in the board coordinate space.\n",
      "        .   * @param imgPoints Vector of vectors of the projections of board marker corner points.\n",
      "    \n",
      "    getPredefinedDictionary(...)\n",
      "        getPredefinedDictionary(dict) -> retval\n",
      "        .   * @brief Returns one of the predefined dictionaries referenced by DICT_*.\n",
      "    \n",
      "    interpolateCornersCharuco(...)\n",
      "        interpolateCornersCharuco(markerCorners, markerIds, image, board[, charucoCorners[, charucoIds[, cameraMatrix[, distCoeffs[, minMarkers]]]]]) -> retval, charucoCorners, charucoIds\n",
      "        .   * @brief Interpolate position of ChArUco board corners\n",
      "        .   * @param markerCorners vector of already detected markers corners. For each marker, its four\n",
      "        .   * corners are provided, (e.g std::vector<std::vector<cv::Point2f> > ). For N detected markers, the\n",
      "        .   * dimensions of this array should be Nx4. The order of the corners should be clockwise.\n",
      "        .   * @param markerIds list of identifiers for each marker in corners\n",
      "        .   * @param image input image necesary for corner refinement. Note that markers are not detected and\n",
      "        .   * should be sent in corners and ids parameters.\n",
      "        .   * @param board layout of ChArUco board.\n",
      "        .   * @param charucoCorners interpolated chessboard corners\n",
      "        .   * @param charucoIds interpolated chessboard corners identifiers\n",
      "        .   * @param cameraMatrix optional 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   * @param distCoeffs optional vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   * @param minMarkers number of adjacent markers that must be detected to return a charuco corner\n",
      "        .   *\n",
      "        .   * This function receives the detected markers and returns the 2D position of the chessboard corners\n",
      "        .   * from a ChArUco board using the detected Aruco markers. If camera parameters are provided,\n",
      "        .   * the process is based in an approximated pose estimation, else it is based on local homography.\n",
      "        .   * Only visible corners are returned. For each corner, its corresponding identifier is\n",
      "        .   * also returned in charucoIds.\n",
      "        .   * The function returns the number of interpolated corners.\n",
      "    \n",
      "    refineDetectedMarkers(...)\n",
      "        refineDetectedMarkers(image, board, detectedCorners, detectedIds, rejectedCorners[, cameraMatrix[, distCoeffs[, minRepDistance[, errorCorrectionRate[, checkAllOrders[, recoveredIdxs[, parameters]]]]]]]) -> detectedCorners, detectedIds, rejectedCorners, recoveredIdxs\n",
      "        .   * @brief Refind not detected markers based on the already detected and the board layout\n",
      "        .   *\n",
      "        .   * @param image input image\n",
      "        .   * @param board layout of markers in the board.\n",
      "        .   * @param detectedCorners vector of already detected marker corners.\n",
      "        .   * @param detectedIds vector of already detected marker identifiers.\n",
      "        .   * @param rejectedCorners vector of rejected candidates during the marker detection process.\n",
      "        .   * @param cameraMatrix optional input 3x3 floating-point camera matrix\n",
      "        .   * \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   * @param distCoeffs optional vector of distortion coefficients\n",
      "        .   * \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6],[s_1, s_2, s_3, s_4]])\\f$ of 4, 5, 8 or 12 elements\n",
      "        .   * @param minRepDistance minimum distance between the corners of the rejected candidate and the\n",
      "        .   * reprojected marker in order to consider it as a correspondence.\n",
      "        .   * @param errorCorrectionRate rate of allowed erroneous bits respect to the error correction\n",
      "        .   * capability of the used dictionary. -1 ignores the error correction step.\n",
      "        .   * @param checkAllOrders Consider the four posible corner orders in the rejectedCorners array.\n",
      "        .   * If it set to false, only the provided corner order is considered (default true).\n",
      "        .   * @param recoveredIdxs Optional array to returns the indexes of the recovered candidates in the\n",
      "        .   * original rejectedCorners array.\n",
      "        .   * @param parameters marker detection parameters\n",
      "        .   *\n",
      "        .   * This function tries to find markers that were not detected in the basic detecMarkers function.\n",
      "        .   * First, based on the current detected marker and the board layout, the function interpolates\n",
      "        .   * the position of the missing markers. Then it tries to find correspondence between the reprojected\n",
      "        .   * markers and the rejected candidates based on the minRepDistance and errorCorrectionRate\n",
      "        .   * parameters.\n",
      "        .   * If camera parameters and distortion coefficients are provided, missing markers are reprojected\n",
      "        .   * using projectPoint function. If not, missing marker projections are interpolated using global\n",
      "        .   * homography, and all the marker corners in the board must have the same Z coordinate.\n",
      "\n",
      "DATA\n",
      "    CORNER_REFINE_CONTOUR = 2\n",
      "    CORNER_REFINE_NONE = 0\n",
      "    CORNER_REFINE_SUBPIX = 1\n",
      "    DICT_4X4_100 = 1\n",
      "    DICT_4X4_1000 = 3\n",
      "    DICT_4X4_250 = 2\n",
      "    DICT_4X4_50 = 0\n",
      "    DICT_5X5_100 = 5\n",
      "    DICT_5X5_1000 = 7\n",
      "    DICT_5X5_250 = 6\n",
      "    DICT_5X5_50 = 4\n",
      "    DICT_6X6_100 = 9\n",
      "    DICT_6X6_1000 = 11\n",
      "    DICT_6X6_250 = 10\n",
      "    DICT_6X6_50 = 8\n",
      "    DICT_7X7_100 = 13\n",
      "    DICT_7X7_1000 = 15\n",
      "    DICT_7X7_250 = 14\n",
      "    DICT_7X7_50 = 12\n",
      "    DICT_ARUCO_ORIGINAL = 16\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv.aruco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_50)\n",
    "#print(aruco_dict.markerSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aruco_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4888f3bde58a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Drawing marker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawMarker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maruco_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msidePixels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m700\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Marker preview'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aruco_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Drawing marker\n",
    "img = aruco.drawMarker(aruco_dict, id = 1, sidePixels = 700)\n",
    "cv.imshow('Marker preview', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.imwrite('Marker_1.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function Board_create:\n",
      "\n",
      "Board_create(...)\n",
      "    Board_create(objPoints, dictionary, ids) -> retval\n",
      "    .   * @brief Provide way to create Board by passing nessesary data. Specially needed in Python.\n",
      "    .   *\n",
      "    .   * @param objPoints array of object points of all the marker corners in the board\n",
      "    .   * @param dictionary the dictionary of markers employed for this board\n",
      "    .   * @param ids vector of the identifiers of the markers in the board\n",
      "    .   *\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d741d50a8478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoard_create\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "help(aruco.Board_create)\n",
    "img.shape\n",
    "frame = img\n",
    "h ,w = frame.shape\n",
    "h/2 ,w/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capOneFrame(camNum):\n",
    "    cap = cv.VideoCapture(camNum)\n",
    "    while True:\n",
    "        grabbed, img = cap.read()\n",
    "        cv.imshow('CAPTURE ONE FRAME FUNC, click q to grab frame', img)\n",
    "        if cv.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv.destroyAllWindows()\n",
    "    cap.release()\n",
    "    return img if grabbed else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, windName='', destroyAll=False):\n",
    "    cv.imshow(windName, img);cv.waitKey(0)\n",
    "    if destroyAll: cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "    \n",
    "    frame_with_markers = aruco.drawDetectedMarkers(frame, corners)\n",
    "    \n",
    "    print(corners)\n",
    "    cv.imshow('frame_with_markers', frame)\n",
    "    \n",
    "    ## printing only 10, and other less importand things\n",
    "    if count==10:\n",
    "        clear_output() #clear()\n",
    "        count=0;\n",
    "    count+=1\n",
    "    if cv.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[348., 284.],\n",
      "        [214., 281.],\n",
      "        [214., 148.],\n",
      "        [350., 146.]]], dtype=float32)]\n",
      "[[2]]\n",
      "[]\n",
      "Order is: RB, LB, LT, RT,zgodnie ze wzkazówkami zegara od punktu początkowego\n"
     ]
    }
   ],
   "source": [
    "def detectMarkers():\n",
    "    frame = cv.imread('detectMarkers_1.png')# capOneFrame(1)\n",
    "    show(frame, 'Input picture')\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = \\\n",
    "    aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "    frame_with_markers = aruco.drawDetectedMarkers(frame, corners)\n",
    "    print(corners)\n",
    "    print(ids)\n",
    "    print(rejectedImgPoints)\n",
    "    print('Order is: RB, LB, LT, RT,zgodnie ze wzkazówkami zegara od punktu początkowego')\n",
    "    show(frame, 'Detected Marker', destroyAll=True)\n",
    "detectMarkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frame = frame.copy()\n",
    "print(f\"Wymiary klatki: {n_frame.shape}\")\n",
    "canny = cv.Canny(n_frame, 100, 200)\n",
    "img = cv.copyMakeBorder(canny, 25, 25, 25, 25,\n",
    "                            cv.BORDER_CONSTANT, value=255)\n",
    "print(f\"edges shape: {img.shape}\")\n",
    "im2, contours, hierarchy  = cv.findContours(img, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)\n",
    "contours.sort(key=cv.contourArea, reverse=True)\n",
    "withContours = np.zeros(im2.shape, dtype=\"uint8\")\n",
    "cv.drawContours(withContours, contours, -1, (255,0,0), thickness=1)\n",
    "cv.imshow('Preview', withContours)\n",
    "cv.imshow('Contours', im2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(aruco.drawDetectedMarkers)\n",
    "print(len(contours))\n",
    "#long = max(contours, key=len)\n",
    "contours.sort(key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function drawContours:\n",
      "\n",
      "drawContours(...)\n",
      "    drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]) -> image\n",
      "    .   @brief Draws contours outlines or filled contours.\n",
      "    .   \n",
      "    .   The function draws contour outlines in the image if \\f$\\texttt{thickness} \\ge 0\\f$ or fills the area\n",
      "    .   bounded by the contours if \\f$\\texttt{thickness}<0\\f$ . The example below shows how to retrieve\n",
      "    .   connected components from the binary image and label them: :\n",
      "    .   @code\n",
      "    .   #include \"opencv2/imgproc.hpp\"\n",
      "    .   #include \"opencv2/highgui.hpp\"\n",
      "    .   \n",
      "    .   using namespace cv;\n",
      "    .   using namespace std;\n",
      "    .   \n",
      "    .   int main( int argc, char** argv )\n",
      "    .   {\n",
      "    .   Mat src;\n",
      "    .   // the first command-line parameter must be a filename of the binary\n",
      "    .   // (black-n-white) image\n",
      "    .   if( argc != 2 || !(src=imread(argv[1], 0)).data)\n",
      "    .   return -1;\n",
      "    .   \n",
      "    .   Mat dst = Mat::zeros(src.rows, src.cols, CV_8UC3);\n",
      "    .   \n",
      "    .   src = src > 1;\n",
      "    .   namedWindow( \"Source\", 1 );\n",
      "    .   imshow( \"Source\", src );\n",
      "    .   \n",
      "    .   vector<vector<Point> > contours;\n",
      "    .   vector<Vec4i> hierarchy;\n",
      "    .   \n",
      "    .   findContours( src, contours, hierarchy,\n",
      "    .   RETR_CCOMP, CHAIN_APPROX_SIMPLE );\n",
      "    .   \n",
      "    .   // iterate through all the top-level contours,\n",
      "    .   // draw each connected component with its own random color\n",
      "    .   int idx = 0;\n",
      "    .   for( ; idx >= 0; idx = hierarchy[idx][0] )\n",
      "    .   {\n",
      "    .   Scalar color( rand()&255, rand()&255, rand()&255 );\n",
      "    .   drawContours( dst, contours, idx, color, FILLED, 8, hierarchy );\n",
      "    .   }\n",
      "    .   \n",
      "    .   namedWindow( \"Components\", 1 );\n",
      "    .   imshow( \"Components\", dst );\n",
      "    .   waitKey(0);\n",
      "    .   }\n",
      "    .   @endcode\n",
      "    .   \n",
      "    .   @param image Destination image.\n",
      "    .   @param contours All the input contours. Each contour is stored as a point vector.\n",
      "    .   @param contourIdx Parameter indicating a contour to draw. If it is negative, all the contours are drawn.\n",
      "    .   @param color Color of the contours.\n",
      "    .   @param thickness Thickness of lines the contours are drawn with. If it is negative (for example,\n",
      "    .   thickness=#FILLED ), the contour interiors are drawn.\n",
      "    .   @param lineType Line connectivity. See #LineTypes\n",
      "    .   @param hierarchy Optional information about hierarchy. It is only needed if you want to draw only\n",
      "    .   some of the contours (see maxLevel ).\n",
      "    .   @param maxLevel Maximal level for drawn contours. If it is 0, only the specified contour is drawn.\n",
      "    .   If it is 1, the function draws the contour(s) and all the nested contours. If it is 2, the function\n",
      "    .   draws the contours, all the nested contours, all the nested-to-nested contours, and so on. This\n",
      "    .   parameter is only taken into account when there is hierarchy available.\n",
      "    .   @param offset Optional contour shift parameter. Shift all the drawn contours by the specified\n",
      "    .   \\f$\\texttt{offset}=(dx,dy)\\f$ .\n",
      "    .   @note When thickness=#FILLED, the function is designed to handle connected components with holes correctly\n",
      "    .   even when no hierarchy date is provided. This is done by analyzing all the outlines together\n",
      "    .   using even-odd rule. This may give incorrect results if you have a joint collection of separately retrieved\n",
      "    .   contours. In order to solve this problem, you need to call #drawContours separately for each sub-group\n",
      "    .   of contours, or iterate over the collection using contourIdx parameter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv.drawContours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#orb = cv2.ORB()\n",
    "## Default parameters of ORB\n",
    "#nfeatures=320;\n",
    "#scaleFactor=1.2;\n",
    "#nlevels=8;\n",
    "#edgeThreshold=; # Changed default (31);\n",
    "#firstLevel=0;\n",
    "#WTA_K=2;\n",
    "#patchSize=31;\n",
    "#fastThreshold=20;\n",
    "\n",
    "\"\"\"\n",
    "orb = cv2.ORB_create(nfeatures,\n",
    "                    scaleFactor,\n",
    "                    nlevels,\n",
    "                    edgeThreshold,\n",
    "                    firstLevel,\n",
    "                    WTA_K,\n",
    "                    patchSize,\n",
    "                    fastThreshold)\n",
    "\"\"\"\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "minpoint = []\n",
    "mindes = []\n",
    "def findNearestKeyPoint(x,y,kp,des):\n",
    "    global minpoint, mindes\n",
    "    mindist = 100000000000\n",
    "    minpoint = kp[0]\n",
    "    mindes = des[0]\n",
    "    index = 0\n",
    "    for point in kp:\n",
    "        dist = (point.pt[0]-x)**2+(point.pt[1]-y)**2\n",
    "        if dist < mindist:\n",
    "            mindist = dist\n",
    "            minpoint = point\n",
    "            mindes = des[index]\n",
    "            #print des[index]\n",
    "        index += 1\n",
    "\n",
    "\n",
    "def service_mouse(event,x,y,flags,param):\n",
    "    global kp, des\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        findNearestKeyPoint(x,y,kp,des)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.setMouseCallback('image',service_mouse)\n",
    "print('Click ESC to close window.')\n",
    "\n",
    "while(1):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret is not True:\n",
    "        raise Exception(\"No frame form camera.\")d\n",
    "        #cv2.waitKey(100)\n",
    "        #continue\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    kp = orb.detect(gray,None)\n",
    "    kp, des = orb.compute(gray, kp)\n",
    "    img2 = cv2.drawKeypoints(frame,kp, frame, color=(0,255,0), flags=0)\n",
    "    if minpoint:\n",
    "        cv2.circle(img2, (int(minpoint.pt[0]),int(minpoint.pt[1])) , 4, [0,0,255],-1 )\n",
    "\n",
    "        matches = bf.match(np.array([mindes]),des)\n",
    "        # suggestions: get list of best, pick closest to knwon position, update descriptors\n",
    "\n",
    "        matches = sorted(matches, key = lambda x:x.distance, reverse=False)\n",
    "        newguy = kp[matches[0].trainIdx].pt\n",
    "        cv2.circle(img2, (int(newguy[0]),int(newguy[1])) , 10, [0,0,255],-1 )\n",
    "\n",
    "\n",
    "    cv2.imshow('image',cv2.pyrDown(img2))\n",
    "\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyCam():\n",
    "    def __init__(self, frameSize=(480, 640), focus=600, avgPointPos=np.array([0, 0, 3]), sigma=.5, pointNum=300):\n",
    "        self.pointCloud = sigma * np.random.randn(pointNum, 3)\n",
    "        self.pointCloud = map(lambda pnt: pnt + avgPointPos, self.pointCloud)\n",
    "        self.t = np.zeros(3)\n",
    "        self.R = np.identity(3)\n",
    "        self.frameSize = frameSize\n",
    "        self.focus = focus\n",
    "\n",
    "    def read(self):\n",
    "        pnts = np.array(self.projectPoints())\n",
    "        frame = np.zeros(self.frameSize + (3,))\n",
    "\n",
    "        for pnt in pnts.astype(int):\n",
    "            if pnt[0] > 0 and pnt[1] > 1 and pnt[0] < self.frameSize[0] and pnt[1] < self.frameSize[1]:\n",
    "                cv2.circle(frame, tuple(pnt), 5, [0, 0, 255], -1)\n",
    "        return frame\n",
    "\n",
    "    def addVecToPoint(self, points, vec):\n",
    "        return map(lambda pnt: pnt + vec, points)\n",
    "\n",
    "    def transformPoints(self):\n",
    "        rotated = np.dot(\n",
    "            self.pointCloud, self.R.T\n",
    "        )\n",
    "        translated = self.addVecToPoint(rotated, self.t)\n",
    "        return translated\n",
    "\n",
    "    def projectPoints(self):\n",
    "        transformed = self.transformPoints()\n",
    "        inFrontofCameraPoints = filter(lambda pnt: pnt[2] > 0, transformed)\n",
    "        return map(lambda pnt: self.focus * pnt[:2]/pnt[2] + np.array(self.frameSize)/2, inFrontofCameraPoints)\n",
    "\n",
    "\n",
    "cam = MyCam()\n",
    "'''\n",
    "frame = cam.read()\n",
    "cv2.imshow('frame',frame)\n",
    "k = cv2.waitKey(0)\n",
    "'''\n",
    "\n",
    "angle = .1\n",
    "\n",
    "rotateZ = np.array([[np.cos(angle), np.sin(angle), 0],\n",
    "                    [-np.sin(angle), np.cos(angle), 0],\n",
    "                    [0, 0, 1]])\n",
    "while(1):\n",
    "    frame = cam.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    cam.R = np.dot(rotate, cam.R)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "rotateX = np.array([[np.cos(angle), np.sin(angle), 0],\n",
    "                    [-np.sin(angle), np.cos(angle), 0],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capOneFrame(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
