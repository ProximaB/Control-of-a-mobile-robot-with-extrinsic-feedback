{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7a25d982c238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maruco\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0maruco\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cls'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import os\n",
    "clear = lambda: os.system('cls')\n",
    "clear()\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-28267b0cb098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maruco\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "help(cv.aruco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "print(aruco_dict.markerSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aruco' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-875ad845cb58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maruco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawMarker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maruco_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msidePixels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m700\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Marker preview'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Marker_1.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aruco' is not defined"
     ]
    }
   ],
   "source": [
    "img = aruco.drawMarker(aruco_dict, id = 1, sidePixels = 700)\n",
    "cv.imshow('Marker preview', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.imwrite('Marker_1.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function Board_create:\n",
      "\n",
      "Board_create(...)\n",
      "    Board_create(objPoints, dictionary, ids) -> retval\n",
      "    .   * @brief Provide way to create Board by passing nessesary data. Specially needed in Python.\n",
      "    .   *\n",
      "    .   * @param objPoints array of object points of all the marker corners in the board\n",
      "    .   * @param dictionary the dictionary of markers employed for this board\n",
      "    .   * @param ids vector of the identifiers of the markers in the board\n",
      "    .   *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(aruco.Board_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capOneFrame(camNum):\n",
    "    cap = cv.VideoCapture(camNum)\n",
    "    while True:\n",
    "        grabbed, img = cap.read()\n",
    "        cv.imshow('CAPTURE ONE FRAME FUNC, click q to grab frame', img)\n",
    "        if cv.waitKey(5) & 0xFF == ord('q'):\n",
    "            break;\n",
    "    return img if grabbed else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, windName='', destroyAll=False):\n",
    "    cv.imshow(windName, img);cv.waitKey(0)\n",
    "    if destroyAll: cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(1)\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "    \n",
    "    frame_with_markers = aruco.drawDetectedMarkers(frame, corners)\n",
    "    \n",
    "    print(corners)\n",
    "    cv.imshow('frame_with_markers', frame)\n",
    "    \n",
    "    ## printing only 10, and other less importand things\n",
    "    if count==10:\n",
    "        clear_output() #clear()\n",
    "        count=0;\n",
    "    count+=1\n",
    "    if cv.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[348., 284.],\n",
      "        [214., 281.],\n",
      "        [214., 148.],\n",
      "        [350., 146.]]], dtype=float32)]\n",
      "Order is: RB, LB, LT, RT,zgodnie ze wzkazówkami zegara od punktu początkowego\n"
     ]
    }
   ],
   "source": [
    "def detectMarkers():\n",
    "    frame = cv.imread('detectMarkers_1.png')# capOneFrame(1)\n",
    "    show(frame, 'Input picture')\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = \\\n",
    "    aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "    frame_with_markers = aruco.drawDetectedMarkers(frame, corners)\n",
    "    print(corners)\n",
    "    print('Order is: RB, LB, LT, RT,zgodnie ze wzkazówkami zegara od punktu początkowego')\n",
    "    show(frame, 'Detected Marker', destroyAll=True)\n",
    "detectMarkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a01bd7879137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Wymiary klatki: {n_frame.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcanny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m img = cv.copyMakeBorder(canny, 25, 25, 25, 25,\n\u001b[0;32m      5\u001b[0m                             cv.BORDER_CONSTANT, value=255)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    }
   ],
   "source": [
    "n_frame = frame.copy()\n",
    "print(f\"Wymiary klatki: {n_frame.shape}\")\n",
    "canny = cv.Canny(n_frame, 100, 200)\n",
    "img = cv.copyMakeBorder(canny, 25, 25, 25, 25,\n",
    "                            cv.BORDER_CONSTANT, value=255)\n",
    "print(f\"edges shape: {img.shape}\")\n",
    "im2, contours, hierarchy  = cv.findContours(img, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)\n",
    "contours.sort(key=cv.contourArea, reverse=True)\n",
    "withContours = np.zeros(im2.shape, dtype=\"uint8\")\n",
    "cv.drawContours(withContours, contours, -1, (255,0,0), thickness=1)\n",
    "cv.imshow('Preview', withContours)\n",
    "cv.imshow('Contours', im2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    }
   ],
   "source": [
    "# help(aruco.drawDetectedMarkers)\n",
    "print(len(contours))\n",
    "#long = max(contours, key=len)\n",
    "contours.sort(key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function drawContours:\n",
      "\n",
      "drawContours(...)\n",
      "    drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]) -> image\n",
      "    .   @brief Draws contours outlines or filled contours.\n",
      "    .   \n",
      "    .   The function draws contour outlines in the image if \\f$\\texttt{thickness} \\ge 0\\f$ or fills the area\n",
      "    .   bounded by the contours if \\f$\\texttt{thickness}<0\\f$ . The example below shows how to retrieve\n",
      "    .   connected components from the binary image and label them: :\n",
      "    .   @include snippets/imgproc_drawContours.cpp\n",
      "    .   \n",
      "    .   @param image Destination image.\n",
      "    .   @param contours All the input contours. Each contour is stored as a point vector.\n",
      "    .   @param contourIdx Parameter indicating a contour to draw. If it is negative, all the contours are drawn.\n",
      "    .   @param color Color of the contours.\n",
      "    .   @param thickness Thickness of lines the contours are drawn with. If it is negative (for example,\n",
      "    .   thickness=#FILLED ), the contour interiors are drawn.\n",
      "    .   @param lineType Line connectivity. See #LineTypes\n",
      "    .   @param hierarchy Optional information about hierarchy. It is only needed if you want to draw only\n",
      "    .   some of the contours (see maxLevel ).\n",
      "    .   @param maxLevel Maximal level for drawn contours. If it is 0, only the specified contour is drawn.\n",
      "    .   If it is 1, the function draws the contour(s) and all the nested contours. If it is 2, the function\n",
      "    .   draws the contours, all the nested contours, all the nested-to-nested contours, and so on. This\n",
      "    .   parameter is only taken into account when there is hierarchy available.\n",
      "    .   @param offset Optional contour shift parameter. Shift all the drawn contours by the specified\n",
      "    .   \\f$\\texttt{offset}=(dx,dy)\\f$ .\n",
      "    .   @note When thickness=#FILLED, the function is designed to handle connected components with holes correctly\n",
      "    .   even when no hierarchy date is provided. This is done by analyzing all the outlines together\n",
      "    .   using even-odd rule. This may give incorrect results if you have a joint collection of separately retrieved\n",
      "    .   contours. In order to solve this problem, you need to call #drawContours separately for each sub-group\n",
      "    .   of contours, or iterate over the collection using contourIdx parameter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv.drawContours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#orb = cv2.ORB()\n",
    "orb = cv2.ORB_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "minpoint = []\n",
    "mindes = []\n",
    "def findNearestKeyPoint(x,y,kp,des):\n",
    "    global minpointP, mindes\n",
    "    mindist = 100000000000\n",
    "    minpoint = kp[0]\n",
    "    mindes = des[0]\n",
    "    index = 0\n",
    "    for point in kp:\n",
    "        dist = (point.pt[0]-x)**2+(point.pt[1]-y)**2\n",
    "        if dist < mindist:\n",
    "            mindist = dist\n",
    "            minpoint = point\n",
    "            mindes = des[index]\n",
    "            #print des[index]\n",
    "        index += 1\n",
    "\n",
    "\n",
    "def service_mouse(event,x,y,flags,param):\n",
    "    global kp, des\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        findNearestKeyPoint(x,y,kp,des)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',service_mouse)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    kp = orb.detect(gray,None)\n",
    "    kp, des = orb.compute(gray, kp)\n",
    "    img2 = cv2.drawKeypoints(frame,kp, frame, color=(0,255,0), flags=0)\n",
    "    if minpoint:\n",
    "        cv2.circle(img2, (int(minpoint.pt[0]),int(minpoint.pt[1])) , 4, [0,0,255],-1 )\n",
    "\n",
    "        matches = bf.match(np.array([mindes]),des)\n",
    "        # suggestions: get list of best, pick closest to knwon position, update descriptors\n",
    "\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        newguy = kp[matches[0].trainIdx].pt\n",
    "        cv2.circle(img2, (int(newguy[0]),int(newguy[1])) , 10, [0,0,255],-1 )\n",
    "\n",
    "\n",
    "    cv2.imshow('image',cv2.pyrDown(img2))\n",
    "\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'map' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c567d6affd87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     [0, 0, 1]])\n\u001b[0;32m     49\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c567d6affd87>\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mpnts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojectPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframeSize\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c567d6affd87>\u001b[0m in \u001b[0;36mprojectPoints\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprojectPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0minFrontofCameraPoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mpnt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpnt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mpnt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfocus\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpnt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpnt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframeSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minFrontofCameraPoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c567d6affd87>\u001b[0m in \u001b[0;36mtransformPoints\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransformPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mrotated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpointCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mtranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddVecToPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'map' and 'float'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyCam():\n",
    "    def __init__(self, frameSize=(480, 640), focus=600, avgPointPos=np.array([0, 0, 3]), sigma=.5, pointNum=300):\n",
    "        self.pointCloud = sigma * np.random.randn(pointNum, 3)\n",
    "        self.pointCloud = map(lambda pnt: pnt + avgPointPos, self.pointCloud)\n",
    "        self.t = np.zeros(3)\n",
    "        self.R = np.identity(3)\n",
    "        self.frameSize = frameSize\n",
    "        self.focus = focus\n",
    "\n",
    "    def read(self):\n",
    "        pnts = np.array(self.projectPoints())\n",
    "        frame = np.zeros(self.frameSize + (3,))\n",
    "\n",
    "        for pnt in pnts.astype(int):\n",
    "            if pnt[0] > 0 and pnt[1] > 1 and pnt[0] < self.frameSize[0] and pnt[1] < self.frameSize[1]:\n",
    "                cv2.circle(frame, tuple(pnt), 5, [0, 0, 255], -1)\n",
    "        return frame\n",
    "\n",
    "    def addVecToPoint(self, points, vec):\n",
    "        return map(lambda pnt: pnt + vec, points)\n",
    "\n",
    "    def transformPoints(self):\n",
    "        rotated = np.dot(self.pointCloud, self.R.T)\n",
    "        translated = self.addVecToPoint(rotated, self.t)\n",
    "        return translated\n",
    "\n",
    "    def projectPoints(self):\n",
    "        transformed = self.transformPoints()\n",
    "        inFrontofCameraPoints = filter(lambda pnt: pnt[2] > 0, transformed)\n",
    "        return map(lambda pnt: self.focus * pnt[:2]/pnt[2] + np.array(self.frameSize)/2, inFrontofCameraPoints)\n",
    "\n",
    "\n",
    "cam = MyCam()\n",
    "'''\n",
    "frame = cam.read()\n",
    "cv2.imshow('frame',frame)\n",
    "k = cv2.waitKey(0)\n",
    "'''\n",
    "\n",
    "angle = .1\n",
    "\n",
    "rotateZ = np.array([[np.cos(angle), np.sin(angle), 0],\n",
    "                    [-np.sin(angle), np.cos(angle), 0],\n",
    "                    [0, 0, 1]])\n",
    "while(1):\n",
    "    frame = cam.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    cam.R = np.dot(rotate, cam.R)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "rotateX = np.array([[np.cos(angle), np.sin(angle), 0],\n",
    "                    [-np.sin(angle), np.cos(angle), 0],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
